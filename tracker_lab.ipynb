{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import mlflow\n",
    "from mlflow import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Работаем над воспроизводимостью\n",
    "torch.random.manual_seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 0. Создаем модель, с которой будем работать\n",
    "# Step 0. Create the model, which we will be working with\n",
    "\n",
    "\n",
    "# Шаг 0.1 Готовим класс датасета для лайтнинга\n",
    "# Step 0.1 Preparing the Dataset class for Pytorch Lightning\n",
    "from pytorch_lightning.core.module import LightningModule\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "\n",
    "\n",
    "class TorchModelData(Dataset):\n",
    "    def __init__(self, X: torch.Tensor, y: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "\n",
    "\n",
    "# Шаг 0.2 Описываем модель\n",
    "class LightningModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_features: int,\n",
    "            layer_neurons: List[int],\n",
    "            activation_function_class,\n",
    "            opt=torch.optim.NAdam,\n",
    "            lr=0.01\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._in_features = in_features\n",
    "        self._layer_neurons = layer_neurons\n",
    "        self._lr = lr\n",
    "        self._opt = opt\n",
    "\n",
    "        layers = []\n",
    "        for i in range(len(layer_neurons)):\n",
    "            if i == 0:\n",
    "                input_neurons = in_features\n",
    "            else:\n",
    "                input_neurons = layer_neurons[i-1]\n",
    "            \n",
    "            layers.append(torch.nn.Linear(input_neurons, layer_neurons[i]))\n",
    "            if i != (len(layer_neurons) - 1):\n",
    "                layers.append(activation_function_class())\n",
    "        \n",
    "        self._model = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self.forward(x)\n",
    "        loss = torch.mean((y - preds)**2)\n",
    "        self.log(\"train_mse\", loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self.forward(x)\n",
    "        loss = torch.mean((y - preds)**2)\n",
    "        self.log(\"val_mse\", loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = self._opt(self.parameters(), lr=self._lr)\n",
    "        return opt\n",
    "    \n",
    "\n",
    "# Шаг 0.3 - создаем обратный вызов pytorch lightning, где будем фиксировать метрики по эпохам\n",
    "# для MLFlow\n",
    "\n",
    "class MlflowMetricCallback(pl.Callback):\n",
    "    def __init__(self, train_tensor, val_tensor, y_train, y_val):\n",
    "        super().__init__()\n",
    "        self._train_X = train_tensor\n",
    "        self._val_X = val_tensor\n",
    "        self._y_train = y_train.detach().cpu().numpy()\n",
    "        self._y_val = y_val.detach().cpu().numpy()\n",
    "\n",
    "    def on_train_epoch_end(self, trainer: Trainer, pl_module: LightningModule):\n",
    "        preds_train = pl_module(self._train_X).detach().cpu().numpy()\n",
    "        preds_val = pl_module(self._val_X).detach().cpu().numpy()\n",
    "\n",
    "        epoch = trainer.current_epoch\n",
    "\n",
    "        metrics = {\n",
    "            \"Train MAE\": mean_absolute_error(self._y_train, preds_train),\n",
    "            \"Train R2\": r2_score(self._y_train, preds_train),\n",
    "            \"Eval MAE\": mean_absolute_error(self._y_val, preds_val),\n",
    "            \"Eval R2\": r2_score(self._y_val, preds_val)\n",
    "        }\n",
    "\n",
    "        mlflow.log_metrics(metrics, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <th>Age (day)</th>\n",
       "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.887366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.269535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.052780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.296075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.284354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.178794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.696601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.768036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.401235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement (component 1)(kg in a m^3 mixture)  \\\n",
       "0                                         540.0   \n",
       "1                                         540.0   \n",
       "2                                         332.5   \n",
       "3                                         332.5   \n",
       "4                                         198.6   \n",
       "...                                         ...   \n",
       "1025                                      276.4   \n",
       "1026                                      322.2   \n",
       "1027                                      148.5   \n",
       "1028                                      159.1   \n",
       "1029                                      260.9   \n",
       "\n",
       "      Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
       "0                                                   0.0       \n",
       "1                                                   0.0       \n",
       "2                                                 142.5       \n",
       "3                                                 142.5       \n",
       "4                                                 132.4       \n",
       "...                                                 ...       \n",
       "1025                                              116.0       \n",
       "1026                                                0.0       \n",
       "1027                                              139.4       \n",
       "1028                                              186.7       \n",
       "1029                                              100.5       \n",
       "\n",
       "      Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "...                                          ...   \n",
       "1025                                        90.3   \n",
       "1026                                       115.6   \n",
       "1027                                       108.6   \n",
       "1028                                         0.0   \n",
       "1029                                        78.3   \n",
       "\n",
       "      Water  (component 4)(kg in a m^3 mixture)  \\\n",
       "0                                         162.0   \n",
       "1                                         162.0   \n",
       "2                                         228.0   \n",
       "3                                         228.0   \n",
       "4                                         192.0   \n",
       "...                                         ...   \n",
       "1025                                      179.6   \n",
       "1026                                      196.0   \n",
       "1027                                      192.7   \n",
       "1028                                      175.6   \n",
       "1029                                      200.6   \n",
       "\n",
       "      Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
       "0                                                   2.5     \n",
       "1                                                   2.5     \n",
       "2                                                   0.0     \n",
       "3                                                   0.0     \n",
       "4                                                   0.0     \n",
       "...                                                 ...     \n",
       "1025                                                8.9     \n",
       "1026                                               10.4     \n",
       "1027                                                6.1     \n",
       "1028                                               11.3     \n",
       "1029                                                8.6     \n",
       "\n",
       "      Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
       "0                                                1040.0      \n",
       "1                                                1055.0      \n",
       "2                                                 932.0      \n",
       "3                                                 932.0      \n",
       "4                                                 978.4      \n",
       "...                                                 ...      \n",
       "1025                                              870.1      \n",
       "1026                                              817.9      \n",
       "1027                                              892.4      \n",
       "1028                                              989.6      \n",
       "1029                                              864.5      \n",
       "\n",
       "      Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \\\n",
       "0                                                 676.0         28   \n",
       "1                                                 676.0         28   \n",
       "2                                                 594.0        270   \n",
       "3                                                 594.0        365   \n",
       "4                                                 825.5        360   \n",
       "...                                                 ...        ...   \n",
       "1025                                              768.3         28   \n",
       "1026                                              813.4         28   \n",
       "1027                                              780.0         28   \n",
       "1028                                              788.9         28   \n",
       "1029                                              761.5         28   \n",
       "\n",
       "      Concrete compressive strength(MPa, megapascals)   \n",
       "0                                            79.986111  \n",
       "1                                            61.887366  \n",
       "2                                            40.269535  \n",
       "3                                            41.052780  \n",
       "4                                            44.296075  \n",
       "...                                                ...  \n",
       "1025                                         44.284354  \n",
       "1026                                         31.178794  \n",
       "1027                                         23.696601  \n",
       "1028                                         32.768036  \n",
       "1029                                         32.401235  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Шаг 1. Загружаем данные\n",
    "data = pd.read_excel(\"Concrete_Data.xls\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"Concrete compressive strength(MPa, megapascals) \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 2. Разбиваем данные на тренировку и валидацию\n",
    "\n",
    "X_train, X_val = train_test_split(data, test_size=0.2, shuffle=True, random_state=42)\n",
    "y_train, y_val = X_train.pop(target_name), X_val.pop(target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "y_train.hist(bins=50, ax=axs[0])\n",
    "y_val.hist(bins=50, ax=axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Трансформируем данные\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "sc = RobustScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "train_tensor = sc.transform(X_train)\n",
    "train_tensor = torch.as_tensor(train_tensor, dtype=torch.float32)\n",
    "\n",
    "val_tensor = sc.transform(X_val)\n",
    "val_tensor = torch.as_tensor(val_tensor, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.as_tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "y_val_tensor = torch.as_tensor(y_val.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем загрузчики данных\n",
    "train_ds = TorchModelData(train_tensor, y_train_tensor)\n",
    "val_ds = TorchModelData(val_tensor, y_val_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=256)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 21    \n",
      "--------------------------------------\n",
      "21        Trainable params\n",
      "0         Non-trainable params\n",
      "21        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 157.24it/s, v_num=42, val_mse=1.52e+3, train_mse=1.57e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 135.89it/s, v_num=42, val_mse=1.52e+3, train_mse=1.57e+3]\n"
     ]
    }
   ],
   "source": [
    "# Обучаем тестовую модель\n",
    "model = LightningModel(\n",
    "    train_tensor.shape[1],\n",
    "    [2, 1],\n",
    "    torch.nn.ReLU\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5, accelerator='cpu')\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlflow-artifacts:/735113632342717487', creation_time=1715598420516, experiment_id='735113632342717487', last_update_time=1715598420516, lifecycle_stage='active', name='Concrete_Models', tags={'mlflow.note.content': 'Experiment on forecasting concrete strength',\n",
      " 'project_name': 'concrete-strength'}>, <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1715594875056, experiment_id='0', last_update_time=1715594875056, lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "# Обучение прошло успешно, подключаем MLFLow\n",
    "# Сначала запустим локальный сервер\n",
    "# Для этого в терминале:\n",
    "# mlflow server --host 127.0.0.1 --port 8080\n",
    "\n",
    "# Далее, при включенном сервере:\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "all_experiments = client.search_experiments()\n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем эксперимент, если его еще нет\n",
    "concrete_experiment = client.search_experiments(\n",
    "    filter_string=\"tags.`project_name` = 'concrete-strength'\"\n",
    ")\n",
    "\n",
    "if len(concrete_experiment) == 0:\n",
    "    experiment_description = (\n",
    "        \"Experiment on forecasting concrete strength\"\n",
    "    )\n",
    "\n",
    "    # Добавляем теги\n",
    "    experiment_tags = {\n",
    "        \"project_name\": \"concrete-strength\",\n",
    "        \"mlflow.note.content\": experiment_description,\n",
    "    }\n",
    "\n",
    "    # Создаем эксперимент, даем ему уникальное имя\n",
    "    concrete_experiment = client.create_experiment(\n",
    "        name=\"Concrete_Models\", tags=experiment_tags\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 41    \n",
      "--------------------------------------\n",
      "41        Trainable params\n",
      "0         Non-trainable params\n",
      "41        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 101.50it/s, v_num=43, val_mse=1.49e+3, train_mse=1.55e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 89.18it/s, v_num=43, val_mse=1.49e+3, train_mse=1.55e+3] \n",
      "{'Final Eval MAE': 35.15579, 'Final Eval R2': -4.780042539483034}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Обучаем нормальный бейзлайн, логируем параметры\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "experiment = mlflow.set_experiment(\"Concrete_Models\")\n",
    "\n",
    "run_name = \"Baseline Model\"\n",
    "artifact_path = \"BaselineModel\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    model_params = {\n",
    "        \"in_features\": train_tensor.shape[1],\n",
    "        \"layer_neurons\": [4, 1],\n",
    "        \"activation_function_class\": torch.nn.ReLU\n",
    "    }\n",
    "\n",
    "    # Обучаем тестовую модель\n",
    "    model = LightningModel(**model_params)\n",
    "\n",
    "    mlflow_callback = MlflowMetricCallback(train_tensor, val_tensor, y_train_tensor, y_val_tensor)\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=15, accelerator='cpu', callbacks=[mlflow_callback])\n",
    "    trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    preds = model(val_tensor)\n",
    "\n",
    "    detached_real = y_val_tensor.detach().cpu().numpy()\n",
    "    detached_pred = preds.detach().cpu().numpy()\n",
    "\n",
    "    metrics = {\n",
    "        \"Final Eval MAE\": mean_absolute_error(detached_real, detached_pred),\n",
    "        \"Final Eval R2\": r2_score(detached_real, detached_pred)\n",
    "    }\n",
    "\n",
    "    # Запишем данные по эксперименту в MLFlow\n",
    " \n",
    "    mlflow.log_params(model_params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.pytorch.log_model(model, artifact_path)\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 41    \n",
      "--------------------------------------\n",
      "41        Trainable params\n",
      "0         Non-trainable params\n",
      "41        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 99.42it/s, v_num=44, val_mse=278.0, train_mse=298.0]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 90.10it/s, v_num=44, val_mse=278.0, train_mse=298.0]\n",
      "{'Final Eval MAE': 12.709404, 'Final Eval R2': 0.07033993794851057}\n"
     ]
    }
   ],
   "source": [
    "# Гипотеза 1: Неподходящий оптимизатор: попробуем SGD\n",
    "run_name = \"SGD Model\"\n",
    "artifact_path = \"SGDModel\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    model_params = {\n",
    "        \"in_features\": train_tensor.shape[1],\n",
    "        \"layer_neurons\": [4, 1],\n",
    "        \"activation_function_class\": torch.nn.ReLU,\n",
    "        \"opt\": torch.optim.SGD,\n",
    "        \"lr\": 0.01\n",
    "    }\n",
    "\n",
    "    # Обучаем тестовую модель\n",
    "    model = LightningModel(**model_params)\n",
    "\n",
    "    mlflow_callback = MlflowMetricCallback(train_tensor, val_tensor, y_train_tensor, y_val_tensor)\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=15, accelerator='cpu', callbacks=[mlflow_callback])\n",
    "    trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    preds = model(val_tensor)\n",
    "\n",
    "    detached_real = y_val_tensor.detach().cpu().numpy()\n",
    "    detached_pred = preds.detach().cpu().numpy()\n",
    "\n",
    "    metrics = {\n",
    "        \"Final Eval MAE\": mean_absolute_error(detached_real, detached_pred),\n",
    "        \"Final Eval R2\": r2_score(detached_real, detached_pred)\n",
    "    }\n",
    "\n",
    "    # Запишем данные по эксперименту в MLFlow\n",
    " \n",
    "    mlflow.log_params(model_params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.pytorch.log_model(model, artifact_path)\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 833   \n",
      "--------------------------------------\n",
      "833       Trainable params\n",
      "0         Non-trainable params\n",
      "833       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 79.77it/s, v_num=45, val_mse=735.0, train_mse=1.01e+3]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4/4 [00:00<00:00, 71.65it/s, v_num=45, val_mse=735.0, train_mse=1.01e+3]\n",
      "{'Final Eval MAE': 21.068789, 'Final Eval R2': -1.4267559497231592}\n"
     ]
    }
   ],
   "source": [
    "# Гипотеза 2: слишком мало нейронов. Попробуем увеличить\n",
    "\n",
    "run_name = \"More Neurons Model\"\n",
    "artifact_path = \"ManyNeuronsModel\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    model_params = {\n",
    "        \"in_features\": train_tensor.shape[1],\n",
    "        \"layer_neurons\": [32, 16, 1],\n",
    "        \"activation_function_class\": torch.nn.ReLU,\n",
    "        \"lr\": 0.01\n",
    "    }\n",
    "\n",
    "    # Обучаем тестовую модель\n",
    "    model = LightningModel(**model_params)\n",
    "\n",
    "    mlflow_callback = MlflowMetricCallback(train_tensor, val_tensor, y_train_tensor, y_val_tensor)\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=15, accelerator='cpu', callbacks=[mlflow_callback])\n",
    "    trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    preds = model(val_tensor)\n",
    "\n",
    "    detached_real = y_val_tensor.detach().cpu().numpy()\n",
    "    detached_pred = preds.detach().cpu().numpy()\n",
    "\n",
    "    metrics = {\n",
    "        \"Final Eval MAE\": mean_absolute_error(detached_real, detached_pred),\n",
    "        \"Final Eval R2\": r2_score(detached_real, detached_pred)\n",
    "    }\n",
    "\n",
    "    # Запишем данные по эксперименту в MLFlow\n",
    " \n",
    "    mlflow.log_params(model_params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.pytorch.log_model(model, artifact_path)\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | _model | Sequential | 121   \n",
      "--------------------------------------\n",
      "121       Trainable params\n",
      "0         Non-trainable params\n",
      "121       Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/a/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 94.19it/s, v_num=46, val_mse=1.14e+3, train_mse=1.22e+3] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 84.36it/s, v_num=46, val_mse=1.14e+3, train_mse=1.22e+3]\n",
      "{'Final Eval MAE': 29.293703, 'Final Eval R2': -3.287185736321133}\n"
     ]
    }
   ],
   "source": [
    "# Гипотеза 3: недостаточно гибкая функция активации. Попробуем GELU + добавим эпох обучения\n",
    "\n",
    "run_name = \"Many Neurons, GELU, more train time\"\n",
    "artifact_path = \"NeuronsGeluTrainTime\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    model_params = {\n",
    "        \"in_features\": train_tensor.shape[1],\n",
    "        \"layer_neurons\": [12, 1],\n",
    "        \"activation_function_class\": torch.nn.GELU,\n",
    "        \"lr\": 0.01\n",
    "    }\n",
    "\n",
    "    # Обучаем тестовую модель\n",
    "    model = LightningModel(**model_params)\n",
    "\n",
    "    mlflow_callback = MlflowMetricCallback(train_tensor, val_tensor, y_train_tensor, y_val_tensor)\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=25, accelerator='cpu', callbacks=[mlflow_callback])\n",
    "    trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    preds = model(val_tensor)\n",
    "\n",
    "    detached_real = y_val_tensor.detach().cpu().numpy()\n",
    "    detached_pred = preds.detach().cpu().numpy()\n",
    "\n",
    "    metrics = {\n",
    "        \"Final Eval MAE\": mean_absolute_error(detached_real, detached_pred),\n",
    "        \"Final Eval R2\": r2_score(detached_real, detached_pred)\n",
    "    }\n",
    "\n",
    "    # Запишем данные по эксперименту в MLFlow\n",
    " \n",
    "    mlflow.log_params(model_params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.pytorch.log_model(model, artifact_path)\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
